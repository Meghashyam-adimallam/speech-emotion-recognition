Perfect â€” this is nearly ready for GitHub! Letâ€™s quickly clean and format the `README.md` properly so it:

* Displays with clean markdown syntax
* Has proper code blocks
* Fixes folder tree formatting

---

## âœ… Final Cleaned `README.md` (Copy This Version)

````markdown
# ğŸ™ï¸ Speech Emotion Recognition with PyTorch + Streamlit

A Deep Learning project that recognizes **human emotions from voice** using **MFCC audio features** and a **BiLSTM model** trained on the RAVDESS dataset. The project includes a full pipeline: preprocessing, training, evaluation, and a real-time Streamlit web app.

---

## ğŸ“Œ Project Highlights

- ğŸ”Š Input: `.wav` audio files (speech only)
- ğŸ¯ Output: Predicted emotion (e.g., happy, sad, angry, calm...)
- ğŸ§  Model: Bidirectional LSTM using PyTorch
- ğŸ“Š Evaluation: Accuracy, F1-score, and confusion matrix
- ğŸ’¬ Web App: Built with Streamlit for real-time emotion detection

---

## ğŸ§  Emotions Detected

The model classifies audio into **8 emotion classes**:

```python
['angry', 'calm', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised']
````

---

## ğŸ“ Folder Structure

```
speech-emotion-recognition/
â”œâ”€â”€ app.py                 # Streamlit UI
â”œâ”€â”€ train.py               # Model training script
â”œâ”€â”€ evaluate.py            # Model evaluation on test data
â”œâ”€â”€ emotion_bilstm.pth     # Trained PyTorch model
â”œâ”€â”€ requirements.txt       # Dependencies list
â”œâ”€â”€ .gitignore             # Git ignore rules
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model.py           # BiLSTM model definition
â”‚   â”œâ”€â”€ dataset.py         # Custom PyTorch Dataset
â”‚   â”œâ”€â”€ preprocessing.py   # Audio feature extraction (MFCC)
â”‚   â””â”€â”€ __init__.py
â””â”€â”€ README.md              # This file
```

---

## ğŸš€ How to Run

### 1. Clone the Repo

```bash
git clone https://github.com/Meghashyam-adimallam/speech-emotion-recognition.git
cd speech-emotion-recognition
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

> Or install manually:

```bash
pip install torch torchaudio librosa matplotlib seaborn scikit-learn streamlit
```

### 3. Train the Model (Optional)

```bash
python train.py
```

### 4. Evaluate on Test Set

```bash
python evaluate.py
```

### 5. Run the Streamlit App

```bash
streamlit run app.py
```

---

## ğŸ™ï¸ Streamlit App Preview

Upload a `.wav` file and see emotion prediction live!

<!-- Optionally add an image here -->

<!-- ![Demo Screenshot](link-to-image.png) -->

---

## ğŸ“¦ Dataset Used

> **RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song)**
> Only the speech audio subset was used.

ğŸ“¥ Download here: [https://zenodo.org/record/1188976](https://zenodo.org/record/1188976)

ğŸ“ **Note**: Audio files are not included in this repo due to size limits.
Please download and place them in:

```
data/raw_audio/Audio_Speech_Actors_01-24/
```

---

## ğŸ“Š Model Performance

* Validation Accuracy: **\~48â€“50%**
* Strong detection for: **angry**, **surprised**, **calm**
* Evaluated using confusion matrix + F1 scores

---

## ğŸ’¡ Future Improvements

* ğŸ¤ Add microphone input support
* ğŸ“ˆ Improve accuracy using spectrograms or CNN layers
* â˜ï¸ Deploy to Hugging Face Spaces or Streamlit Cloud

---

## ğŸ‘¤ Author

**Meghashyam Adimallam**
[GitHub Profile â†’](https://github.com/Meghashyam-adimallam)

---

## ğŸ“œ License

This project is under the [MIT License](LICENSE).

````

---

### âœ… What To Do Now:
1. Replace the content of your current `README.md` with the cleaned version above
2. Save it
3. Commit & push:
```bash
git add README.md
git commit -m "Update cleaned README"
git push
````

---
